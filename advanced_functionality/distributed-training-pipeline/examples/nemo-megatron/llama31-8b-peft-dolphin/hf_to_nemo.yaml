resources:
  instance_count: 1
  instance_type: ml.g5.48xlarge
  volume_size: 400
pre_script: 
  - SCRIPT_DIR=/NeMo/scripts/checkpoint_converters
  - cd $SCRIPT_DIR
  - mkdir -p $LOG_ROOT
  - OUTPUT_LOG=$LOG_ROOT/hf_to_nemo.log
  - TMP_MODEL_PATH=/tmp/model
  - cp -r $MODEL_PATH $TMP_MODEL_PATH
  - 'if [ -f $TMP_MODEL_PATH/tokenizer.model ]; then rm -f $TMP_MODEL_PATH/tokenizer.model; fi'
post_script:
  - cp -r $TMP_MODEL_PATH/ckpt.nemo $MODEL_PATH/
train:
  env:
    - name: LOG_ROOT
      value: $SM_CHANNEL_EFS/home/$RELEASE_NAME/logs
    - name: MODEL_PATH
      value: "$SM_CHANNEL_FSX/huggingface/models/$HF_MODEL_ID/$HF_MODEL_REVISION"
  command:
    - python3
  args:
    - convert_llama_hf_to_nemo.py
    - --input_name_or_path=$TMP_MODEL_PATH 
    - --output_path=$TMP_MODEL_PATH/ckpt.nemo
    - --llama31=True
    - '2>&1'

# PEFT Llama2 7B on pubmedqa dataset using Nemo Meagtron-LM

This example shows how to do parameter efficient fine tuning (PEFT) of [Llama2-7B](https://huggingface.co/meta-llama/Llama-2-7b-hf) model on [pubmedqa](https://github.com/pubmedqa/pubmedqa/tree/master) dataset using [Nemo](https://github.com/NVIDIA/NeMo) [Megatron-LM](https://github.com/NVIDIA/Megatron-LM).  
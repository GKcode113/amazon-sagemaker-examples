huggingface:
  model: "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
  revision: "ebf7e8d03db3d86a442d22d30d499abb7ec27bea"
  download: true
djl:
  engine: "Python"
  option.entryPoint: "djl_python.tensorrt_llm"
  option.model_loading_timeout: 1800
  option.tensor_parallel_degree: 8
  option.max_rolling_batch_size: 8
  option.output_formatter: "json"
  option.max_num_tokens: 8192
  option.dtype: "fp16"
  option.trust_remote_code: true
sagemaker:
  model:
    name: "deepseek-r1-distill-llama-8b-tensorrt-llm"
    container: "containers/tensorrt-llm"
    
  endpoint:
    name: "deepseek-r1-distill-llama-8b-tensorrt-llm"
    instance_type: "ml.g5.48xlarge"
    initial_instance_count: 1
    variant_name: "test"
    model_data_download_timeout_secs: 1800
    container_startup_health_check_timeout_secs: 1200
test:
  module_name: "llama3_prompt_generator"
  module_dir: "modules/inst-semeval2017"
  prompt_generator: "PromptGenerator"
  template: { "inputs": "", "parameters": { "do_sample": true, "max_new_tokens": 1024, "top_k": 50 }  }
  template_keys: ["inputs"]
  warmup_iters: 1
  max_iters: 10
  n_concurrent: 4
  output_dir: "output"
  locust_users: 24
  locust_workers: 4
